# Configuration file for PyISV - Autoencoder

# General settings and metadata
experiment_name: "default_autoencoder_run"
description: "Baseline autoencoder training for RDF images."
notes: "Set use_ddp=True for distributed training. Adjust embed_dim, batch_size, and learning_rate for sweeps."

general:
  device: "auto"
  seed: 42
  apply_jit_tracing: False # Use JIT tracing for model optimization

# Model settings
model:
  type: "autoencoder"     # Options: "autoencoder", "classifier"
  input_shape: [1, 320]   # number of channels, number of bins
  encoder_channels: [8, 16, 32, 64, 64, 128, 128]
  decoder_channels: [128, 128, 64, 64, 32, 16, 8]
  activation_fn: "ReLU"
  embed_dim: 2            # Bottleneck size
  kernel_size: 3          # Kernel size used in convolutional layers
  use_pooling: True       # Use pooling layers in the model

# Training settings
training:
  batch_size: 256         # Batch size for training
  train_fraction: 0.8
  min_epochs: 75   
  max_epochs: 350
  learning_rate: 0.002
  scheduled_lr: True      # Use learning rate scheduler
  early_stopping:
    patience: 10
    delta: 0.00005
  num_workers: 4           # Number of workers for data loading
  pin_memory: True         # Load data into memory for faster access
  use_ddp: True            # Use Distributed Data Parallel

# Data settings
input:
  dataset: "rdf_images.pt"      # Name of the input dataset for autoencoder
  target: null                  # Autoencoder uses the same input as target
  normalization: "minmax"       # Options: "minmax", "gaussian"

# Output settings
output:
  model_name: "best_autoencoder_model.pt"
  log_file: "train_autoencoder_log.txt"
  stats_file: "train_autoencoder_stats.txt"
  model_architecture_file: "autoencoder_architecture.txt"
  normalization_params:
    divval_inputs: "input_autoen_scaler_subval.npy"
    subval_inputs: "input_autoen_scaler_divval.npy"
    divval_targets: "target_autoen_scaler_subval.npy"
    subval_targets: "target_autoen_scaler_divval.npy"