# Configuration file for PyISV - Autoencoder

# Experiment metadata
experiment_name: "default_autoencoder_run"
description: "Baseline autoencoder training for RDF images."
notes: "Set USE_DDP=1 for distributed training. Adjust embed_dim, batch_size, and learning_rate for sweeps."

# General settings
seed: 42

# Model settings
model:
  type: "autoencoder"     # Options: "autoencoder", "classifier"
  input_shape: [1, 320]   # number of channels, number of bins
  encoder_channels: [8, 16, 32, 64, 64, 128, 128]
  decoder_channels: [128, 128, 64, 64, 32, 16, 8]
  activation_fn: "ReLU"
  embed_dim: 2            # Bottleneck size
  kernel_size: 3          # Kernel size used in convolutional layers

# Training settings
training:
  batch_size: 256         # Batch size for training
  train_fraction: 0.8
  min_epochs: 75   
  max_epochs: 350
  learning_rate: 0.002
  scheduled_lr: True      # Use learning rate scheduler
  early_stopping:
    patience: 10
    delta: 0.00005
  use_ddp: True            # Use Distributed Data Parallel
  num_workers: 4           # Number of workers for data loading
  pin_memory: True         # Load data into memory for faster access

# Data settings
input:
  path: "./data/RDFs/rdf_images.pt"  # Path for the input dataset for autoencoder
  target_path: null                  # Autoencoder uses the same input as target
  normalization: "minmax"            # Options: "minmax", "gaussian"

# Output settings
output:
  model_name: "./models/best_autoencoder_model.pt"
  log_file: "./logs/train_autoencoder_log.txt"
  stats_file: "./stats/train_autoencoder_stats.txt"
  model_architecture_file: "./models/autoencoder_architecture.txt"
  normalization_params:
    input_scaler_subval: "norm_vals/input_autoen_scaler_subval.npy"
    input_scaler_divval: "norm_vals/input_autoen_scaler_divval.npy"
    target_scaler_subval: "norm_vals/target_autoen_scaler_subval.npy"
    target_scaler_divval: "norm_vals/target_autoen_scaler_divval.npy"