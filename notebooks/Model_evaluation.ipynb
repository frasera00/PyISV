{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d9bcc4",
   "metadata": {},
   "source": [
    "This notebook section provides visualizations and analysis of the autoencoder model's performance and outputs. The following cells include:\n",
    "\n",
    "- Plotting a histogram of reconstruction errors to assess model accuracy.\n",
    "- Displaying training and validation loss curves to monitor learning progress.\n",
    "- Visualizing the learned latent space embeddings with a scatter plot.\n",
    "- Instructions and code for exporting the trained PyTorch model to ONNX format and visualizing its architecture using Netron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d712c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from PyISV.neural_network import NeuralNetwork  # Import your model class\n",
    "\n",
    "RUN_ID = \"20250517_203607\"\n",
    "\n",
    "# Common project paths\n",
    "from PyISV.utils.define_root import PROJECT_ROOT as root_dir\n",
    "\n",
    "# Paths to the data\n",
    "data_dir = os.path.join(root_dir, \"datasets\")\n",
    "model_dir = os.path.join(root_dir, \"models/\", RUN_ID)\n",
    "outputs_dir = os.path.join(model_dir, \"outputs\")\n",
    "norms_dir = os.path.join(model_dir, \"norms\")\n",
    "stats_dir = os.path.join(model_dir, \"stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35147d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, model_path, inputs_path):\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))  # Adjust path\n",
    "    model.eval()\n",
    "\n",
    "    # 2. Prepare your dataset\n",
    "    inputs = np.load(inputs_path)  # Or load your data as needed\n",
    "    inputs_tensor = torch.from_numpy(inputs).float()  # Convert to tensor\n",
    "\n",
    "    # 3. Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs, latent = model(inputs_tensor)\n",
    "\n",
    "    outputs = outputs.numpy()  # Convert to numpy array if needed\n",
    "    latent = latent.numpy()  # Convert latent representation to numpy array if needed\n",
    "\n",
    "    return outputs, latent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c83245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructed_vs_input(inputs, outputs, sample_idx):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(inputs[sample_idx, 0, 25:], label=\"Input\", color=\"blue\")\n",
    "    ax.plot(outputs[sample_idx, 0, 25:], label=\"Reconstructed\", color=\"orange\")\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Sample {sample_idx}\")\n",
    "    ax.set_xlabel(\"Index\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "inputs = np.load(f\"{data_dir}/RDFs/RDFs.npy\")\n",
    "outputs = torch.load(f\"{outputs_dir}/outputs.npy\")\n",
    "\n",
    "print(f\"Inputs shape: {inputs.shape}\")\n",
    "print(f\"Outputs shape: {outputs.shape}\")\n",
    "\n",
    "plot_reconstructed_vs_input(inputs, outputs, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71252488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_errors(recon_errors_file, bins=50):\n",
    "    \"\"\"\n",
    "    Plot the histogram of reconstruction errors.\n",
    "    \"\"\"\n",
    "    errors = np.load(recon_errors_file)\n",
    "    print(errors)\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.hist(errors, bins=bins)\n",
    "    ax.set_xlabel('Reconstruction error'); ax.set_ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "reconstruction_errors(\n",
    "    os.path.join(f'{outputs_dir}/evaluation', f'{RUN_ID}_reconstructed_errors.npy'),\n",
    "    bins=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(stats_file):\n",
    "    \"\"\"\n",
    "    Plot the training and validation loss curves from a CS\"V file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(stats_file)\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(df['epoch'], df['train_loss'], label='train')\n",
    "    ax.plot(df['epoch'], df['val_loss'],   label='val')\n",
    "    ax.set_xlabel('Epoch'); ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.set_yscale('log')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_loss_curve(\n",
    "    os.path.join(f'{stats_dir}', f'{RUN_ID}_train_autoencoder_stats.dat')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_scatter(embedding_file):\n",
    "    \"\"\"\n",
    "    Plot a scatter plot of the embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = np.load(embedding_file)\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.scatter(embeddings[:,0], embeddings[:,1])\n",
    "    ax.set_xlabel('CV1'); ax.set_ylabel('CV2')\n",
    "    plt.tight_layout()\n",
    "\n",
    "embedding_scatter(\n",
    "    os.path.join(f'{outputs_dir}/evaluation', f'{RUN_ID}_embeddings.npy')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092f811",
   "metadata": {},
   "source": [
    "## Export PyTorch Model to ONNX and Visualize with Netron\n",
    "\n",
    "This section demonstrates how to export your trained PyTorch model to the ONNX format and visualize its architecture using Netron.\n",
    "\n",
    "\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Load your model class and weights.\n",
    "\n",
    "2. Create a dummy input tensor matching your model's input shape.\n",
    "\n",
    "3. Export the model to ONNX.\n",
    "\n",
    "4. Visualize the ONNX file with Netron.\n",
    "\n",
    "\n",
    "\n",
    "> **Note:** You must have the model class definition available in the notebook. If it's in another file, import it accordingly. Adjust the dummy input shape if your model expects a different input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ca111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with Netron\n",
    "# Can be installed via pip: pip install netron\n",
    "# or conda: conda install -c conda-forge netron\n",
    "import netron\n",
    "\n",
    "onnx_path = f\"{model_dir}/model.onnx\"\n",
    "netron.start(onnx_path)\n",
    "# This will open a browser window with the model visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
