{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d86bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PyISV.utils.training_utils import Dataset, PreloadedDataset\n",
    "from PyISV.neural_network import NeuralNetwork\n",
    "from PyISV.utils.validation_utils import Validator\n",
    "from PyISV.utils.set_architecture import import_config\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbc4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded inputs: torch.Size([72000, 1, 340]), targets: torch.Size([72000, 1, 340])\n"
     ]
    }
   ],
   "source": [
    "# ---- Config ----\n",
    "input_file = root_dir+\"/datasets/RDFs/nonMin_nCu_38.pt\"  # e.g. \"datasets/RDFs/min_nCu_38.pt\"\n",
    "target_file = root_dir+\"/datasets/RDFs/min_nCu_38.pt\"  # can be same as input for identity test\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 16\n",
    "\n",
    "# ---- Load Data ----\n",
    "inputs = torch.load(input_file)\n",
    "targets = torch.load(target_file)\n",
    "print(f\"Loaded inputs: {inputs.shape}, targets: {targets.shape}\")\n",
    "\n",
    "# ---- Dataset and DataLoader ----\n",
    "dataset = Dataset(inputs, targets, norm_inputs=True, norm_targets=True, norm_mode=\"minmax\")\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261d782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature map length: 7\n",
      "Calculated flattened dimension: 896\n",
      "Configuration Summary:\n",
      "Run ID: test_run\n",
      "DDP Enabled: True\n",
      "Batch Size: 128\n",
      "Number of Workers: 16\n",
      "Learning Rate: 0.001\n",
      "\n",
      "=== Available CPU Resources ===\n",
      "CPUs available to PyTorch: 48\n",
      "Num of OpenMP threads: 16\n",
      "\n",
      "=== Available GPU Resources ===\n",
      "GPUs available to PyTorch: 3\n",
      "Name of GPU devices: ['NVIDIA A30', 'NVIDIA A30', 'NVIDIA A30']\n",
      "Visible CUDA devices: 0,1,2\n"
     ]
    }
   ],
   "source": [
    "#Configure training parameters\n",
    "import math\n",
    "import datetime\n",
    "import torch.distributed as dist\n",
    "\n",
    "# Clean up any existing process groups\n",
    "if dist.is_initialized():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "# Get input and target data paths\n",
    "input_data = root_dir+\"datasets/RDFs/min_nCu_38.pt\"\n",
    "target_data = root_dir+\"datasets/RDFs/min_nCu_38.pt\"\n",
    "\n",
    "# Enable DDP\n",
    "use_ddp = True\n",
    "\n",
    "# Model architecture parameters\n",
    "embed_dim = 3\n",
    "in_channels = 1\n",
    "input_length = 340\n",
    "n_features = 340 * in_channels\n",
    "\n",
    "# Encoder architecture\n",
    "channels = [8, 16, 32, 64, 64, 128]  # out_channels for each Conv1d\n",
    "kernel_sizes = [3, 3, 3, 3, 3, 3]\n",
    "paddings = [2, 2, 2, 2, 2, 2]\n",
    "strides = [1, 1, 1, 1, 1, 1]\n",
    "pool_kernel = 2\n",
    "pool_stride = 2\n",
    "\n",
    "length = input_length\n",
    "for i in range(len(channels)):\n",
    "    length = math.floor((length + 2*paddings[i] - (kernel_sizes[i]-1) - 1)/strides[i] + 1)\n",
    "    length = math.floor((length - pool_kernel)/pool_stride + 1)\n",
    "\n",
    "last_layer_length = channels[-1]\n",
    "flat_dim = last_layer_length * length\n",
    "feature_map_length = length\n",
    "print(f\"Final feature map length: {length}\")\n",
    "print(f\"Calculated flattened dimension: {flat_dim}\")\n",
    "\n",
    "params = {\n",
    "  \"GENERAL\": {\n",
    "    \"device\": \"cuda\",\n",
    "    \"seed\": 42,\n",
    "    \"apply_jit_tracing\": False,\n",
    "    \"use_ddp\": use_ddp,\n",
    "    \"use_lr_finder\": False,\n",
    "    \"use_tensorboard\": False,\n",
    "    \"input_length\": 340,\n",
    "    \"input_channels\": in_channels,\n",
    "    \"input_features\": n_features,\n",
    "    \"flattened_features\": n_features\n",
    "  },\n",
    "  \"MODEL\": {\n",
    "    \"type\": \"autoencoder\",\n",
    "    \"input_shape\": [in_channels, n_features],\n",
    "    \"embedding_dim\": embed_dim,\n",
    "    \"flattened_dim\": flat_dim,\n",
    "    \"feature_map_length\": feature_map_length,\n",
    "    \"encoder_layers\": [\n",
    "      [\n",
    "        {\"type\": \"Conv1d\", \"in_channels\": in_channels, \"out_channels\": 8, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"MaxPool1d\", \"kernel_size\": 2, \"stride\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 8}\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Conv1d\", \"in_channels\": 8, \"out_channels\": 16, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"MaxPool1d\", \"kernel_size\": 2, \"stride\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 16}\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Conv1d\", \"in_channels\": 16, \"out_channels\": 32, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"MaxPool1d\", \"kernel_size\": 2, \"stride\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 32}\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Conv1d\", \"in_channels\": 32, \"out_channels\": 64, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"MaxPool1d\", \"kernel_size\": 2, \"stride\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 64}  \n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Conv1d\", \"in_channels\": 64, \"out_channels\": 64, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"MaxPool1d\", \"kernel_size\": 2, \"stride\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 64}\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Conv1d\", \"in_channels\": 64, \"out_channels\": 128, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"MaxPool1d\", \"kernel_size\": 2, \"stride\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 128}\n",
    "      ]\n",
    "    ],\n",
    "    \"bottleneck_layers\": [\n",
    "      [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Linear\", \"in_features\": flat_dim, \"out_features\": embed_dim},\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Linear\", \"in_features\": embed_dim, \"out_features\": flat_dim},\n",
    "        {\"type\": \"Sigmoid\"}\n",
    "      ]\n",
    "    ],\n",
    "    \"decoder_layers\": [\n",
    "      [\n",
    "        {\"type\": \"Upsample\", \"scale_factor\": 2},\n",
    "        {\"type\": \"ConvTranspose1d\", \"in_channels\": last_layer_length, \"out_channels\": 64, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 64}\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Upsample\", \"scale_factor\": 2},\n",
    "        {\"type\": \"ConvTranspose1d\", \"in_channels\": 64, \"out_channels\": 64, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 64}\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Upsample\", \"scale_factor\": 2},\n",
    "        {\"type\": \"ConvTranspose1d\", \"in_channels\": 64, \"out_channels\": 32, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 32}\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Upsample\", \"scale_factor\": 2},\n",
    "        {\"type\": \"ConvTranspose1d\", \"in_channels\": 32, \"out_channels\": 16, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 16}\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Upsample\", \"scale_factor\": 2},\n",
    "        {\"type\": \"ConvTranspose1d\", \"in_channels\": 16, \"out_channels\": 8, \"kernel_size\": 3, \"padding\": 2},\n",
    "        {\"type\": \"ReLU\"},\n",
    "        {\"type\": \"BatchNorm1d\", \"num_features\": 8}\n",
    "      ],\n",
    "      [\n",
    "        {\"type\": \"Upsample\", \"scale_factor\": 2},\n",
    "        {\"type\": \"Conv1d\", \"in_channels\": 8, \"out_channels\": in_channels, \"kernel_size\": 3, \"padding\": 2},\n",
    "      ]\n",
    "    ]\n",
    "  },\n",
    "  \"TRAINING\": {\n",
    "    # Training parameters\n",
    "    \"batch_size\": 128,\n",
    "    \"train_size\": 0.8,\n",
    "    \"min_epochs\": 100,\n",
    "    \"max_epochs\": 200,\n",
    "    \"loss_function\": \"MSELoss\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"normalization\": \"minmax\",\n",
    "    # Optimizer parameters\n",
    "    \"num_workers\": 16,\n",
    "    \"pin_memory\": True,\n",
    "    \"gradient_clipping\": False,\n",
    "    \"accumulation_steps\": 1,\n",
    "    \"scheduled_lr\": False,\n",
    "    \"scheduler_params\": {\n",
    "      \"lr_warmup_epochs\": 50,\n",
    "      \"milestones\": [],\n",
    "        \"gamma\": 0.5\n",
    "    },\n",
    "    \"early_stopping\": False,\n",
    "    \"early_stopping_params\": {\n",
    "      \"patience\": 30,\n",
    "      \"min_delta\": 0.0001\n",
    "    },\n",
    "  },\n",
    "  \"INPUTS\": {\n",
    "    \"dataset\": input_data,\n",
    "    \"target\": target_data\n",
    "  }\n",
    "}\n",
    "\n",
    "# Save json configuration\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "run_id = \"test_run\"\n",
    "model_id_dir = root_dir+f\"/models/{run_id}\"\n",
    "os.makedirs(model_id_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{model_id_dir}/config.json\", 'w') as f:\n",
    "    json.dump(params, f, indent=4)\n",
    "\n",
    "# Set up environment variables\n",
    "import random\n",
    "master_port = random.randint(29500, 30000)  # Random port for DDP\n",
    "os.environ.update({\n",
    "    #\"NCCL_DEBUG\": \"INFO\",\n",
    "    \"NCCL_SOCKET_IFNAME\": \"^lo,docker\",  # Skip loopback and docker interfaces\n",
    "    \"NCCL_IB_DISABLE\": \"0\",              # Enable InfiniBand if available\n",
    "    \"NCCL_P2P_DISABLE\": \"0\",             # Ensure P2P is enabled\n",
    "    \"TORCH_NCCL_BLOCKING_WAIT\": \"1\",     # Use blocking wait for better performance\n",
    "    \"NCCL_LL_THRESHOLD\": \"0\",            # Disable low latency threshold \n",
    "    \"MASTER_PORT\": str(master_port),\n",
    "    \"MASTER_ADDR\": \"localhost\",\n",
    "    \"WORLD_SIZE\": str(torch.cuda.device_count()),\n",
    "    \"OMP_NUM_THREADS\": \"16\",  # Set OpenMP threads to 1\n",
    "    \"MKL_THREADING_LAYER\": \"INTEL\",  # Set MKL threading layer to Intel\n",
    "    \"KMP_BLOCKTIME\": \"0\",  # Set KMP block time to 0\n",
    "    \"KMP_AFFINITY\": \"granularity=fine,compact,1,0\",  # Set KMP affinity\n",
    "    \"KMP_HW_SUBSET\": \"1t\",  # Use only physical cores, no hyperthreading\n",
    "    \"I_MPI_PIN_DOMAIN\": \"auto\",  # Automatically pin MPI processes to cores\n",
    "    \"I_MPI_PIN\": \"ON\",  # Enable process pinning\n",
    "    \"I_MPI_PIN_CELL\": \"core\",  # Pin MPI processes to cores\n",
    "    \"CUDA_VISIBLE_DEVICES\": \",\".join(str(i) for i in range(torch.cuda.device_count())),\n",
    "    \"PYTHONPATH\": f\"{root_dir}:{os.environ.get('PYTHONPATH', '')}\"\n",
    "})\n",
    "\n",
    "# Print configuration summary\n",
    "print(\"Configuration Summary:\")\n",
    "print(f\"Run ID: {run_id}\")\n",
    "print(f\"DDP Enabled: {use_ddp}\")\n",
    "print(f\"Batch Size: {params['TRAINING']['batch_size']}\")\n",
    "print(f\"Number of Workers: {params['TRAINING']['num_workers']}\")\n",
    "print(f\"Learning Rate: {params['TRAINING']['learning_rate']}\")\n",
    "\n",
    "# Check for generic variables that might be available\n",
    "torch.set_num_threads(int(os.environ.get('OMP_NUM_THREADS', 1)))\n",
    "print(\"\\n=== Available CPU Resources ===\")\n",
    "print(f\"CPUs available to PyTorch: {torch.get_num_interop_threads()}\")\n",
    "print(f\"Num of OpenMP threads: {torch.get_num_threads()}\")\n",
    "\n",
    "print(\"\\n=== Available GPU Resources ===\")\n",
    "print(f\"GPUs available to PyTorch: {torch.cuda.device_count()}\")\n",
    "print(f\"Name of GPU devices: {[torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]}\")\n",
    "print(f\"Visible CUDA devices: {os.environ.get('CUDA_VISIBLE_DEVICES', 'None')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba02d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: torchrun --nproc_per_node=3 --nnodes=1 /scratch/rasera/PyISV/tests/run_test.py\n",
      "Loaded inputs: torch.Size([72000, 1, 340]), targets: torch.Size([72000, 1, 340])\n",
      "Loaded inputs: torch.Size([72000, 1, 340]), targets: torch.Size([72000, 1, 340])\n",
      "Loaded inputs: torch.Size([72000, 1, 340]), targets: torch.Size([72000, 1, 340])\n",
      "Model created.\n",
      "Model created.\n",
      "Model created.\n",
      "Testing with train_epoch_step + validation:\n",
      "Testing with train_epoch_step + validation:\n",
      "Testing with train_epoch_step + validation:\n",
      "Epoch 0: train_loss=0.008665, val_loss=0.006012\n",
      "Epoch 0: train_loss=0.007802, val_loss=0.005782\n",
      "  Val output stats: mean=0.3291, std=0.2863, min=-0.0590, max=1.0468\n",
      "  Val output stats: mean=0.3304, std=0.2774, min=-0.0329, max=1.0329\n",
      "Epoch 0: train_loss=0.007452, val_loss=0.005805\n",
      "  Val output stats: mean=0.3266, std=0.2920, min=-0.0455, max=1.0233\n",
      "Epoch 1: train_loss=0.006077, val_loss=0.006041\n",
      "  Val output stats: mean=0.3308, std=0.2868, min=-0.0344, max=1.0414\n",
      "Epoch 1: train_loss=0.006003, val_loss=0.005822\n",
      "  Val output stats: mean=0.3335, std=0.2763, min=-0.0271, max=1.0147\n",
      "Epoch 1: train_loss=0.006057, val_loss=0.005914\n",
      "  Val output stats: mean=0.3249, std=0.2897, min=-0.0353, max=1.0501\n",
      "Epoch 2: train_loss=0.005906, val_loss=0.005698\n",
      "  Val output stats: mean=0.3328, std=0.2812, min=-0.0268, max=1.0193\n",
      "Test completed successfully.\n",
      "Epoch 2: train_loss=0.005845, val_loss=0.005808\n",
      "  Val output stats: mean=0.3287, std=0.2768, min=-0.0235, max=1.0490\n",
      "Test completed successfully.\n",
      "Epoch 2: train_loss=0.005885, val_loss=0.005764\n",
      "  Val output stats: mean=0.3298, std=0.2858, min=-0.0270, max=1.0197\n",
      "Test completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    \"torchrun\",\n",
    "    f\"--nproc_per_node={torch.cuda.device_count()}\",\n",
    "    \"--nnodes=1\",\n",
    "    f\"{root_dir}/tests/run_test.py\",\n",
    "]\n",
    "\n",
    "print(f\"Running command: {' '.join(cmd)}\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(cmd, check=True, text=True, capture_output=False)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Training failed with error code:\", e.returncode)\n",
    "    print(\"Output:\\n\", e.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62cc1f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created.\n",
      "Testing with train_epoch_step + validation:\n",
      "Epoch 0: train_loss=0.040390, val_loss=0.002859\n",
      "  Val output stats: mean=0.3283, std=0.2990, min=-0.1592, max=1.0668\n",
      "Epoch 1: train_loss=0.002548, val_loss=0.002226\n",
      "  Val output stats: mean=0.3309, std=0.3004, min=-0.1369, max=1.1014\n",
      "Epoch 2: train_loss=0.002133, val_loss=0.001970\n",
      "  Val output stats: mean=0.3297, std=0.2973, min=-0.1126, max=1.0258\n",
      "Epoch 3: train_loss=0.001936, val_loss=0.001794\n",
      "  Val output stats: mean=0.3287, std=0.2975, min=-0.0863, max=1.0333\n",
      "Epoch 4: train_loss=0.001805, val_loss=0.001852\n",
      "  Val output stats: mean=0.3265, std=0.2979, min=-0.0794, max=1.0619\n",
      "Epoch 5: train_loss=0.001726, val_loss=0.001656\n",
      "  Val output stats: mean=0.3264, std=0.2950, min=-0.0741, max=1.0228\n",
      "Epoch 6: train_loss=0.001662, val_loss=0.001609\n",
      "  Val output stats: mean=0.3295, std=0.3024, min=-0.0798, max=1.0324\n",
      "Epoch 7: train_loss=0.001601, val_loss=0.001571\n",
      "  Val output stats: mean=0.3283, std=0.3015, min=-0.0665, max=1.0376\n",
      "Epoch 8: train_loss=0.001544, val_loss=0.001541\n",
      "  Val output stats: mean=0.3344, std=0.3014, min=-0.0437, max=1.0363\n",
      "Epoch 9: train_loss=0.001526, val_loss=0.001513\n",
      "  Val output stats: mean=0.3291, std=0.2985, min=-0.0521, max=1.0456\n"
     ]
    }
   ],
   "source": [
    "from PyISV.utils.IO_utils import load_tensor\n",
    "from PyISV.utils.set_architecture import import_config\n",
    "from PyISV.utils.training_utils import Dataset, get_data_loader, PreloadedDataset, get_device\n",
    "\n",
    "# Use set_architecture to normalize the config\n",
    "config = import_config(json_file=root_dir+\"/models/test_run/config.json\")\n",
    "model_config = config[\"MODEL\"]\n",
    "model = NeuralNetwork(model_config).to(config[\"GENERAL\"][\"device\"])\n",
    "print(\"Model created.\")\n",
    "\n",
    "# ---- Loss and Optimizer ----\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from PyISV.utils.training_utils import train_epoch_step\n",
    "from PyISV.utils.validation_utils import Validator\n",
    "\n",
    "# ---- Create validator ----\n",
    "validator_config = model_config  # Use the same config\n",
    "validator = Validator(validator_config)\n",
    "\n",
    "# ---- Prepare data ----\n",
    "\n",
    "input_file = config['INPUTS']['dataset']\n",
    "target_file = config['INPUTS']['target']\n",
    "input_data = load_tensor(input_file)\n",
    "target_data = load_tensor(target_file) if target_file else input_data.clone()\n",
    "        \n",
    "dataset = Dataset(\n",
    "    input_data, target_data,\n",
    "    norm_inputs=True, norm_targets=True,\n",
    "    norm_mode=config[\"TRAINING\"][\"normalization\"], device=config[\"GENERAL\"][\"device\"]\n",
    ")\n",
    "\n",
    " # Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    dataset.inputs, dataset.targets,\n",
    "    train_size=config[\"TRAINING\"][\"train_size\"],\n",
    "    random_state=config[\"GENERAL\"][\"seed\"],\n",
    "    shuffle=True, stratify=None\n",
    ")\n",
    "\n",
    "# Loads the data using pre-computed normalization\n",
    "train_dataset = PreloadedDataset(X_train, y_train)\n",
    "valid_dataset = PreloadedDataset(X_valid, y_valid)\n",
    "\n",
    "# Save the validation dataset\n",
    "#torch.save(self.valid_dataset.inputs.detach().cpu(), \n",
    "#           f\"{self.outputs_dir}/input_validation_data.pt\")\n",
    "\n",
    "train_loader = get_data_loader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"TRAINING\"][\"batch_size\"],\n",
    "    num_workers=config[\"TRAINING\"][\"num_workers\"],\n",
    "    pin_memory=config[\"TRAINING\"][\"pin_memory\"],\n",
    "    use_ddp=False,\n",
    "    shuffle=True,\n",
    ")\n",
    "valid_loader = get_data_loader(\n",
    "    valid_dataset,\n",
    "    batch_size=config[\"TRAINING\"][\"batch_size\"],\n",
    "    num_workers=config[\"TRAINING\"][\"num_workers\"],\n",
    "    pin_memory=config[\"TRAINING\"][\"pin_memory\"],\n",
    "    use_ddp=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# ---- Loss and Optimizer ----\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scaler = torch.amp.GradScaler()\n",
    "device = get_device(config[\"GENERAL\"][\"device\"])\n",
    "\n",
    "# ---- Test with train_epoch_step + validation ----\n",
    "print(\"Testing with train_epoch_step + validation:\")\n",
    "for epoch in range(10):\n",
    "    # Training step\n",
    "    avg_train_loss = train_epoch_step(\n",
    "        model=model,\n",
    "        data_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        scaler=scaler,\n",
    "        loss_function=loss_fn,\n",
    "        device=device,\n",
    "        use_ddp=False,\n",
    "        gradient_clipping=None,\n",
    "        accumulation_steps=1,\n",
    "        epoch=epoch\n",
    "    )\n",
    "    \n",
    "    # Validation step\n",
    "    avg_val_loss = validator.validate_epoch(\n",
    "        model=model,\n",
    "        data_loader=valid_loader,\n",
    "        loss_function=loss_fn,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(f\"Epoch {epoch}: train_loss={avg_train_loss:.6f}, val_loss={avg_val_loss:.6f}\")\n",
    "    \n",
    "    # Check a sample batch to see output stats\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_batch = next(iter(valid_loader))\n",
    "        inp, targ = sample_batch\n",
    "        inp, targ = inp.to(device), targ.to(device)\n",
    "        out = model(inp)\n",
    "        if isinstance(out, tuple):\n",
    "            out = out[0]\n",
    "        print(f\"  Val output stats: mean={out.mean().item():.4f}, std={out.std().item():.4f}, min={out.min().item():.4f}, max={out.max().item():.4f}\")\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ccc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---- Single-Batch Overfit Test ----\n",
    "# single_batch = next(iter(train_loader))\n",
    "# inp, targ = single_batch\n",
    "# inp, targ = inp.to(device), targ.to(device)\n",
    "\n",
    "# print(f\"Input min/max: {inp.min().item():.4f}, {inp.max().item():.4f}\")\n",
    "# print(f\"Target min/max: {targ.min().item():.4f}, {targ.max().item():.4f}\")\n",
    "# print(f\"Number of model parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# # Check if parameters update\n",
    "# first_param_before = next(model.parameters()).clone()\n",
    "\n",
    "# for step in range(100):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     out = model(inp)\n",
    "#     if isinstance(out, tuple):\n",
    "#         out = out[0]\n",
    "#     loss = loss_fn(out, targ)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print(f\"Step {step}: loss={loss.item():.6f}\")\n",
    "#     print(f\"  Output stats: mean={out.mean().item():.4f}, std={out.std().item():.4f}, min={out.min().item():.4f}, max={out.max().item():.4f}\")\n",
    "\n",
    "# first_param_after = next(model.parameters()).clone()\n",
    "# print(f\"Parameter changed: {not torch.equal(first_param_before, first_param_after)}\")\n",
    "# print(f\"Parameter difference norm: {(first_param_after - first_param_before).norm().item():.8f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04734d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Compare with simple training loop + validation ----\n",
    "print(\"\\nTesting with simple training loop + validation:\")\n",
    "model_simple = NeuralNetwork(model_config).to(device)  # Fresh model\n",
    "optimizer_simple = torch.optim.Adam(model_simple.parameters(), lr=0.001)\n",
    "validator_simple = Validator(validator_config)\n",
    "\n",
    "for epoch in range(3):\n",
    "    # Simple training\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for batch_idx, (inp, targ) in enumerate(train_loader):\n",
    "        inp, targ = inp.to(device), targ.to(device)\n",
    "        optimizer_simple.zero_grad()\n",
    "        out = model_simple(inp)\n",
    "        if isinstance(out, tuple):\n",
    "            out = out[0]\n",
    "        loss = loss_fn(out, targ)\n",
    "        loss.backward()\n",
    "        optimizer_simple.step()\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_train_loss = total_loss / num_batches\n",
    "    \n",
    "    # Validation with validator\n",
    "    avg_val_loss = validator_simple.validate_epoch(\n",
    "        model=model_simple,\n",
    "        data_loader=val_loader,\n",
    "        loss_function=loss_fn,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(f\"Epoch {epoch}: train_loss={avg_train_loss:.6f}, val_loss={avg_val_loss:.6f}\")\n",
    "    \n",
    "    # Check a sample batch to see output stats\n",
    "    model_simple.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_batch = next(iter(val_loader))\n",
    "        inp, targ = sample_batch\n",
    "        inp, targ = inp.to(device), targ.to(device)\n",
    "        out = model_simple(inp)\n",
    "        if isinstance(out, tuple):\n",
    "            out = out[0]\n",
    "        print(f\"  Val output stats: mean={out.mean().item():.4f}, std={out.std().item():.4f}, min={out.min().item():.4f}, max={out.max().item():.4f}\")\n",
    "    model_simple.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
